{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silent-ozone",
   "metadata": {},
   "source": [
    "# How to Perform Cross-DAAC S3 Bucket Access Using Python\n",
    "### Author: Chris Battisto\n",
    "### Date Authored: 10-02-22\n",
    "\n",
    "### Timing\n",
    "\n",
    "Exercise: 20 minutes\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div style=\"background:#fc9090;border:1px solid #cccccc;padding:5px 10px;\"><big><b>Note:  </b>This notebook <em><strong>will only run in an environment with <a href=\"https://disc.gsfc.nasa.gov/information/glossary?title=AWS%20region\">us-west-2 AWS access</a></strong></em>.</big></div>\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook demonstrates how to access cloud-hosted GES DISC granules using the [Commmon Metadata Repository (CMR) API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html), from two different DAACs ([GES DISC](disc.gsfc.nasa.gov) and [PO.DAAC](https://podaac.jpl.nasa.gov/)).\n",
    "It then plots these two variables at a single time step.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook was written using Python 3.8, and requires these libraries and files: \n",
    "- netrc file with valid Earthdata Login credentials.\n",
    "  - [How to Generate Earthdata Prerequisite Files](https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Generate%20Earthdata%20Prerequisite%20Files)\n",
    "- Xarray\n",
    "- S3FS\n",
    "- Boto3\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "- Cartopy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-eugene",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pprint\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311fcad-48a0-492b-b6b5-2357526d7bad",
   "metadata": {},
   "source": [
    "### Check AWS Region before running notebook\n",
    "\n",
    "A common error when executing this notebook occurs when the notebook is run outside of the us-west-2 AWS region. Here, we check the region using the Boto3 Python library, and throw a ValueError if you are outside the region.\n",
    "\n",
    "This cell is not necessary to access the S3 buckets for users inside the us-west-2 region, and can be commented out or deleted at the users' discretion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8d684e-0015-44dd-90c2-f0cb30f5fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### us-west-2 Region Check: &#x2705;"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (boto3.client('s3').meta.region_name == 'us-west-2'):\n",
    "    display(Markdown('### us-west-2 Region Check: &#x2705;'))\n",
    "else:\n",
    "    display(Markdown('### us-west-2 Region Check: &#10060;'))\n",
    "    raise ValueError('Your notebook is not running inside the AWS us-west-2 region, and will not be able to directly access NASA Earthdata S3 buckets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-identifier",
   "metadata": {},
   "source": [
    "### Retrieve Granule S3 Links\n",
    "\n",
    "First, for [M2T1NXSLV](https://search.earthdata.nasa.gov/search/granules?p=C1276812863-GES_DISC&pg[0][v]=f&pg[0][gsk]=-start_date&q=m2t1nxslv&ff=Available%20from%20AWS%20Cloud&fdc=Goddard%20Earth%20Sciences%20Data%20and%20Information%20Services%20Center%20(GES%20DISC)&tl=1658766017!3!!&lat=-0.140625&long=0.0703125):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "phantom-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First granule S3 URL:\n",
      "{'href': 's3://gesdisc-cumulus-prod-protected/MERRA2/M2T1NXSLV.5.12.4/2012/10/MERRA2_400.tavg1_2d_slv_Nx.20121025.nc4',\n",
      " 'hreflang': 'en-US',\n",
      " 'rel': 'http://esipfed.org/ns/fedsearch/1.1/s3#',\n",
      " 'title': 'This link provides direct download access via S3 to the granule'}\n",
      "S3 Token Endpoint:\n",
      "{'href': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials',\n",
      " 'hreflang': 'en-US',\n",
      " 'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
      " 'title': 'api endpoint to retrieve temporary credentials valid for '\n",
      "          'same-region direct s3 access (VIEW RELATED INFORMATION)'}\n"
     ]
    }
   ],
   "source": [
    "cmr_url = 'https://cmr.earthdata.nasa.gov/search/granules'\n",
    "\n",
    "merra_response = requests.get(cmr_url, \n",
    "                                params={\n",
    "                                    'concept_id': 'C1276812863-GES_DISC',\n",
    "                                    'temporal': '2012-10-25T00:00:00Z',\n",
    "                                    'page_size': 200,\n",
    "                                    },\n",
    "                                headers={\n",
    "                                    'Accept': 'application/json'\n",
    "                                    }\n",
    "                               )\n",
    "\n",
    "# Parse out links from the JSON response:\n",
    "\n",
    "print('First granule S3 URL:') \n",
    "pprint.pprint(merra_response.json()['feed']['entry'][0]['links'][1])\n",
    "print('S3 Token Endpoint:')\n",
    "pprint.pprint(merra_response.json()['feed']['entry'][0]['links'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-essence",
   "metadata": {},
   "source": [
    "Then, for [GHRSST](https://podaac.jpl.nasa.gov/dataset/MUR-JPL-L4-GLOB-v4.1?ids=&values=&provider=POCLOUD#):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "growing-taxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First granule S3 URL:\n",
      "{'href': 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20121025090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n",
      " 'hreflang': 'en-US',\n",
      " 'rel': 'http://esipfed.org/ns/fedsearch/1.1/s3#',\n",
      " 'title': 'This link provides direct download access via S3 to the granule.'}\n",
      "S3 Token Endpoint:\n",
      "{'href': 'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n",
      " 'hreflang': 'en-US',\n",
      " 'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
      " 'title': 'api endpoint to retrieve temporary credentials valid for '\n",
      "          'same-region direct s3 access'}\n"
     ]
    }
   ],
   "source": [
    "ghrsst_response = requests.get(cmr_url, \n",
    "                                params={\n",
    "                                    'concept_id': 'C1996881146-POCLOUD',\n",
    "                                    'temporal': '2012-10-25T00:00:00Z',\n",
    "                                    'page_size': 200,\n",
    "                                    },\n",
    "                                headers={\n",
    "                                    'Accept': 'application/json'\n",
    "                                    }\n",
    "                               )\n",
    "\n",
    "print('First granule S3 URL:') \n",
    "pprint.pprint(ghrsst_response.json()['feed']['entry'][0]['links'][0])\n",
    "print('S3 Token Endpoint:')\n",
    "pprint.pprint(ghrsst_response.json()['feed']['entry'][0]['links'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-computer",
   "metadata": {},
   "source": [
    "### Obtain S3 Credentials and Open Bucket Granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ambient-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for S3 access credentials\n",
    "\n",
    "def begin_s3_direct_access(daac_url):\n",
    "    response = requests.get(daac_url).json()\n",
    "    \n",
    "    return s3fs.S3FileSystem(key=response['accessKeyId'],\n",
    "                             secret=response['secretAccessKey'],\n",
    "                             token=response['sessionToken'],\n",
    "                             client_kwargs={'region_name':'us-west-2'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "personal-business",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/simplejson/__init__.py:525\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    522\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    523\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_decimal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/simplejson/decoder.py:372\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    371\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[0;32m--> 372\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/simplejson/decoder.py:402\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    401\u001b[0m         idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m podaac_s3 \u001b[38;5;241m=\u001b[39m ghrsst_response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeed\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Open S3 file systems with S3FS\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m gesdisc_fs \u001b[38;5;241m=\u001b[39m \u001b[43mbegin_s3_direct_access\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgesdisc_s3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m podaac_fs \u001b[38;5;241m=\u001b[39m begin_s3_direct_access(podaac_s3)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check that the file system is intact as an S3FileSystem object, which means that token is valid\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Common causes of rejected S3 access tokens include incorrect passwords stored in the netrc file, or a non-existent netrc file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mbegin_s3_direct_access\u001b[0;34m(daac_url)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin_s3_direct_access\u001b[39m(daac_url):\n\u001b[0;32m----> 4\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaac_url\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s3fs\u001b[38;5;241m.\u001b[39mS3FileSystem(key\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccessKeyId\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                              secret\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecretAccessKey\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m                              token\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionToken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m                              client_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_name\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-west-2\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Get tokens from GES DISC and PODAAC:\n",
    "\n",
    "gesdisc_s3 = merra_response.json()['feed']['entry'][0]['links'][3]['href']\n",
    "podaac_s3 = ghrsst_response.json()['feed']['entry'][0]['links'][4]['href']\n",
    "\n",
    "# Open S3 file systems with S3FS\n",
    "\n",
    "gesdisc_fs = begin_s3_direct_access(gesdisc_s3)\n",
    "podaac_fs = begin_s3_direct_access(podaac_s3)\n",
    "\n",
    "# Check that the file system is intact as an S3FileSystem object, which means that token is valid\n",
    "# Common causes of rejected S3 access tokens include incorrect passwords stored in the netrc file, or a non-existent netrc file\n",
    "\n",
    "type(gesdisc_fs)\n",
    "type(podaac_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-birthday",
   "metadata": {},
   "source": [
    "### Open Granules in Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filesets\n",
    "merra_fn = merra_response.json()['feed']['entry'][0]['links'][1]['href']\n",
    "\n",
    "ghrsst_fn = ghrsst_response.json()['feed']['entry'][0]['links'][0]['href']\n",
    "\n",
    "# Open datasets with S3FS\n",
    "merra_ds = xr.open_dataset(gesdisc_fs.open(merra_fn))\n",
    "ghrsst_ds = xr.open_dataset(podaac_fs.open(ghrsst_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-contract",
   "metadata": {},
   "source": [
    "Clip to extent over where the hurricane was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lon = -89\n",
    "min_lat = 14\n",
    "max_lon = -67\n",
    "max_lat = 31\n",
    "\n",
    "merra_ds = merra_ds.sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "ghrsst_ds = ghrsst_ds.sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-vehicle",
   "metadata": {},
   "source": [
    "### Convert Dataset Grids\n",
    "\n",
    "First, we need to interpolate the GHRSST grid to the MERRA grid using Xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghrsst_ds = ghrsst_ds.interp(lat=merra_ds.lat, lon=merra_ds.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghrsst_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0c7f9",
   "metadata": {},
   "source": [
    "### Plot Variables using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-configure streamplot vectors\n",
    "\n",
    "u=merra_ds.U2M\n",
    "v=merra_ds.V2M\n",
    "lon=merra_ds.lon\n",
    "lat=merra_ds.lat\n",
    "\n",
    "lons, lats = np.meshgrid(lon, lat)\n",
    "\n",
    "# Plotting routines\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 15, 15\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent([-89, -67, 14, 31], crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.5, zorder=5) \n",
    "ax.add_feature(cfeature.LAND, facecolor='white', zorder=1) \n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.5, zorder=5)\n",
    "ax.add_feature(cfeature.STATES, zorder=5)\n",
    "\n",
    "mmp = ax.pcolormesh(lons, lats, ghrsst_ds.analysed_sst.isel(time=0), \n",
    "              cmap='hot', transform=ccrs.PlateCarree(), zorder=1)\n",
    "    \n",
    "ax.streamplot(lons, lats, u.isel(time=0).values, v.isel(time=0).values, zorder=4, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "\n",
    "cbar = plt.colorbar(mmp, pad=0.1)\n",
    "cbar.set_label(\"Analyzed SST (K)\")\n",
    "\n",
    "fig.suptitle(\"GHRSST Analyzed SST and MERRA-2 2M Wind Streamlines on 2012-10-25T00:00:00Z\", size=16, y=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-release",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
